# -*- coding: utf-8 -*-
"""Stock_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WgQN5nMELkaGGgwpzVv2qyMj814_exvo
"""

import numpy as np
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, LSTM
import pandas as pd #load csv

data = pd.read_csv("/Users/dhjoo/Desktop/Workspace/stock/archive/individual_stocks_5yr/individual_stocks_5yr/AAPL_data.csv")

'''
data.iloc[:,6]=data.iloc[:,4]-data.iloc[:,1]
for i in range(len(data.iloc[:,6])):
  if data.iloc[i,6] > 0:
    data.iloc[i,6] = 0 #상승
  else:
    data.iloc[i,6] = 1 #하락
'''
data.iloc[:,6] = np.where(data.iloc[:,4]-data.iloc[:,1] > 0, [0], [1]) #pythonic

#pd.to_pickle(data, "./with_label") no need to load data with pickle, thus getting rid of unnecessary iloc
np.save('labeled_data',data)

#labeled = pd.read_pickle("with_label") #-> cannot input to model
labeled = np.load("labeled_data.npy",allow_pickle=True) #-> straight input to model

'''
using pandas
train_data = labeled.iloc[:1000,:]
test_data = labeled.iloc[1000:,:]
'''
train_data = labeled[:1000,:]
test_data = labeled[1000:,:]

'''
not continuous data
train_data_stack = np.array(train_data.iloc[:,1:6])
train_data_stack = train_data_stack.reshape([-1,100])
'''

#train_data_np = np.array(train_data)
train_data_np = train_data
train_data_stack = np.zeros((1000-19,100))
for i in range(1000-19):
  train_data_stack[i,:] = train_data_np[i:i+20,1:6].reshape([-1,100])
train_label = train_data_np[19:,6]

#test_data_np = np.array(test_data)
test_data_np = test_data
test_data_stack = np.zeros((259-19,100))
for i in range(259-19):
  test_data_stack[i,:] = test_data_np[i:i+20,1:6].reshape([-1,100])
test_label = test_data_np[19:,6]

encoder = {k:v for v,k in enumerate([0,1])}
y_train = [encoder[i] for i in train_label]
y_train = keras.utils.to_categorical(y_train)
y_test = [encoder[i] for i in test_label]
y_test = keras.utils.to_categorical(y_test)

print("finished")

model = Sequential()
model.add(Dense(100, activation='relu', input_shape=(100,)))
model.add(Dense(150, activation='relu'))
model.add(Dense(200, activation='relu'))
model.add(Dense(150, activation='relu'))
model.add(Dense(100, activation='relu'))
model.add(Dense(2, activation='softmax'))

model.compile(loss='mean_squared_error',
              optimizer='adam',
              metrics=['accuracy'])

hist = model.fit(train_data_stack, y_train,
                    batch_size=10,
                    epochs=100,
                    verbose=0)

score = model.evaluate(test_data_stack, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])
