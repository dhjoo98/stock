# -*- coding: utf-8 -*-
"""Stock_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WgQN5nMELkaGGgwpzVv2qyMj814_exvo
"""

import numpy as np
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, LSTM
import pandas as pd #load csv
'''
data = pd.read_csv("/Users/dhjoo/Desktop/Workspace/stock/archive/individual_stocks_5yr/individual_stocks_5yr/AAPL_data.csv")

data.iloc[:,6] = np.where(data.iloc[:,4]-data.iloc[:,1] > 0, [0], [1]) #pythonic

#pd.to_pickle(data, "./with_label") no need to load data with pickle, thus getting rid of unnecessary iloc
np.save('labeled_data',data)
'''
#labeled = pd.read_pickle("with_label") #-> cannot input to model
labeled = np.load("labeled_data.npy",allow_pickle=True) #-> straight input to model

print(labeled.shape)

data_stack = np.zeros((labeled.shape[0]-19,100))
for i in range(labeled.shape[0]-19):
    data_stack[i,:] = labeled[i:i+20,1:6].reshape([-1,100])
label = labeled[19:,6]
print(data_stack.__class__, label.shape)
sum = np.hstack((data_stack,label.reshape((1240,1))))

#shuffle
np.random.shuffle(sum) #direct shuffling of sum
print(sum.shape)
train_data = sum[:1000,:-1]
test_data = sum[1000:,:-1]
train_label = sum[:1000,-1]
test_label = sum[1000:,-1]
print(train_label.shape)

encoder = {k:v for v,k in enumerate([0,1])}
y_train = [encoder[i] for i in train_label]
y_train = keras.utils.to_categorical(y_train)
y_test = [encoder[i] for i in test_label]
y_test = keras.utils.to_categorical(y_test)

print("data is prepared")

model = Sequential()
model.add(Dense(100, activation='relu', input_shape=(100,)))
model.add(Dense(150, activation='relu'))
model.add(Dense(200, activation='relu'))
model.add(Dense(150, activation='relu'))
model.add(Dense(100, activation='relu'))
model.add(Dense(2, activation='softmax'))

model.compile(loss='mean_squared_error',
              optimizer='adam',
              metrics=['accuracy'])

hist = model.fit(train_data, y_train,
                    batch_size=10,
                    epochs=100,
                    verbose=0)

score = model.evaluate(test_data_stack, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])
